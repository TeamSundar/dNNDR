{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596382572206",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from functions import MODEL\n",
    "\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import max_norm\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Activation, Concatenate, Layer\n",
    "from keras.layers import Conv1D, Add, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Embedding, Bidirectional, GlobalMaxPooling1D, LSTM\n",
    "import keras.backend as K\n",
    "\n",
    "obj = MODEL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 76784/76784 [01:08<00:00, 1123.22it/s]\n"
    }
   ],
   "source": [
    "# Import and process level 2 data\n",
    "drug_smiles = pd.read_csv('data/smiles.csv')[['drug','smile']]  # Drug index dataframe\n",
    "drug_smiles['seq_char_count'] = drug_smiles['smile'].apply(lambda x: len(str(x)))   # Add column with character count\n",
    "drug_smiles = drug_smiles[drug_smiles['smile'].notnull()]   # Remove drugs with no smile strings\n",
    "DTI_index = pd.read_csv('data/final_clean_DTI.csv')[['target','drug','IC50','unit']]\n",
    "DTI_index = DTI_index[DTI_index['drug'].isin(drug_smiles['drug'].tolist())]     # Exclude drugs for which smils are not available\n",
    "DTI_index = DTI_index.reset_index(drop=True)\n",
    "mapping = pd.read_csv('data/chembl2uniprot.txt', header=None, sep='\\t')\n",
    "mapping = mapping[mapping[0].isin(DTI_index['target'].unique())]    # Select targets that are present in data (DTI_index)\n",
    "targets = os.listdir('data/fasta_968')  # List all target fasta files\n",
    "\n",
    "# Categorize drug-target pairs by IC50 values (Make labels)\n",
    "act = []\n",
    "bct = []\n",
    "for i in tqdm(range(DTI_index.shape[0])):\n",
    "    if DTI_index['IC50'][i]<=0.1:\n",
    "        act.append('active')\n",
    "    elif DTI_index['IC50'][i]>0.1 and DTI_index['IC50'][i]<=30:\n",
    "        act.append('intermediate')\n",
    "    elif DTI_index['IC50'][i]>30:\n",
    "        act.append('inactive')\n",
    "    bct.append(mapping[mapping[0]==DTI_index['target'][i]][1].values[0])\n",
    "    \n",
    "DTI_index['activity'] = act\n",
    "DTI_index['target_uniprot'] = bct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 968/968 [00:05<00:00, 180.63it/s]\n"
    }
   ],
   "source": [
    "# Fetch fasta sequences form files and create target index dataframe\n",
    "def fetchFasta(targets):\n",
    "    target_seq = pd.DataFrame(columns=['target_uniprot','target_chembl','seq'])\n",
    "    for fasta in tqdm(targets):\n",
    "        if fasta.split('.')[0] in mapping[1].tolist():\n",
    "            f = open('data/fasta_968/'+fasta,'r')\n",
    "            lines = \"\".join(line.strip() for line in f.readlines()[1:])\n",
    "            dict = {'target_uniprot':fasta.split('.')[0],'target_chembl':mapping[(mapping[1]==fasta.split('.')[0])][0].values[0], 'seq':lines}\n",
    "            target_seq = target_seq.append(dict, True)\n",
    "            f.close()\n",
    "    return target_seq\n",
    "\n",
    "target_seq = fetchFasta(targets)\n",
    "# Length of sequence in train data.\n",
    "#target_seq['seq_char_count'] = target_seq['seq'].apply(lambda : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split indics into train/test\n",
    "train_indices, test_indices = obj.split(DTI_index, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(61427, 1) (61427, 1) (15357, 1) (15357, 1) (61427, 1) (15357, 1)\n"
    }
   ],
   "source": [
    "# Train and test data\n",
    "train_target = DTI_index.loc[train_indices][['target_uniprot']]\n",
    "train_drug = DTI_index.loc[train_indices][['drug']]\n",
    "test_target = DTI_index.loc[test_indices][['target_uniprot']]\n",
    "test_drug = DTI_index.loc[test_indices][['drug']]\n",
    "\n",
    "# Labels\n",
    "train_y = DTI_index.loc[train_indices][['activity']]\n",
    "test_y = DTI_index.loc[test_indices][['activity']]\n",
    "\n",
    "print(train_target.shape, train_drug.shape, test_target.shape, test_drug.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 61427/61427 [00:49<00:00, 1243.45it/s]\n"
    }
   ],
   "source": [
    "# Add uniprot IDs to data index\n",
    "seq = []\n",
    "for target in tqdm(train_target['target_uniprot']):\n",
    "    try:\n",
    "        seq.append(target_seq[target_seq['target_uniprot']==target]['seq'].values[0])\n",
    "    except:\n",
    "        print(target)\n",
    "train_target['seq'] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 61427/61427 [03:59<00:00, 256.34it/s]\n"
    }
   ],
   "source": [
    "# Add smile strings to labels\n",
    "seq = []\n",
    "for drug in tqdm(train_drug['drug']):\n",
    "    try:\n",
    "        seq.append(drug_smiles[drug_smiles['drug']==drug]['smile'].values[0])\n",
    "    except:\n",
    "        print(target)\n",
    "train_drug['seq'] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# plt.subplot(1, 1, 1)\n",
    "# obj.plot_seq_count(drug_smiles, 'Train')\n",
    "\n",
    "# code_freq = obj.get_code_freq(target_seq['seq'], 'Train')\n",
    "# plt.subplot(1, 1, 1)\n",
    "# obj.plot_code_freq(code_freq, 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20}\nTarget Dict Length: 20\n{'3': 1, 'a': 2, 'n': 3, 'F': 4, '#': 5, 'l': 6, 'N': 7, 'o': 8, '.': 9, '7': 10, 'e': 11, '1': 12, '6': 13, '2': 14, 's': 15, '\\\\': 16, 'S': 17, '-': 18, '8': 19, 'Z': 20, 'r': 21, 'A': 22, '4': 23, '[': 24, 'c': 25, ')': 26, '@': 27, 'K': 28, 'i': 29, 'I': 30, '/': 31, '(': 32, '9': 33, '=': 34, '+': 35, 'H': 36, 'B': 37, 'L': 38, '5': 39, ']': 40, 'P': 41, 'C': 42, 'O': 43}\nDrug dict Length: 43\n"
    }
   ],
   "source": [
    "# Encode amino acides and smile characters\n",
    "codes_target = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "         'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "char_dict_target = obj.create_dict(codes_target)\n",
    "\n",
    "codes_drug = [char for char in ''.join(set(''.join(drug_smiles['smile'].values)))]\n",
    "char_dict_drug = obj.create_dict(codes_drug)\n",
    "\n",
    "print(char_dict_target)\n",
    "print(\"Target Dict Length:\", len(char_dict_target))\n",
    "\n",
    "print(char_dict_drug)\n",
    "print(\"Drug dict Length:\", len(char_dict_drug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encode_target = obj.integer_encoding(train_target, char_dict_target) \n",
    "train_encode_drug = obj.integer_encoding(train_drug, char_dict_drug) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((61427, 1000), (61427, 1000))"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# padding sequences\n",
    "max_length = 1000\n",
    "train_pad_target = pad_sequences(train_encode_target, maxlen=max_length, padding='post', truncating='post')\n",
    "train_pad_drug = pad_sequences(train_encode_drug, maxlen=max_length, padding='post', truncating='post')\n",
    "train_pad_target.shape, train_pad_drug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((61427, 1000, 21), (61427, 1000, 44))"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# One hot encoding of sequences\n",
    "train_ohe_target = to_categorical(train_pad_target)\n",
    "train_ohe_drug = to_categorical(train_pad_drug)\n",
    "train_ohe_target.shape, train_ohe_drug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(61427,)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# label/integer encoding output variable: (y)\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(train_y['activity'].tolist())\n",
    "y_train_le.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(61427, 3)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# One hot encoding of outputs\n",
    "y_train = to_categorical(y_train_le)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention class\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"functional_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_5 (InputLayer)            [(None, 1000)]       0                                            \n__________________________________________________________________________________________________\ninput_6 (InputLayer)            [(None, 1000)]       0                                            \n__________________________________________________________________________________________________\nembedding_4 (Embedding)         (None, 1000, 128)    2688        input_5[0][0]                    \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, 1000, 128)    5632        input_6[0][0]                    \n__________________________________________________________________________________________________\nconv1d_4 (Conv1D)               (None, 1000, 32)     12320       embedding_4[0][0]                \n__________________________________________________________________________________________________\nconv1d_5 (Conv1D)               (None, 1000, 32)     12320       embedding_5[0][0]                \n__________________________________________________________________________________________________\nmax_pooling1d_4 (MaxPooling1D)  (None, 500, 32)      0           conv1d_4[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling1d_5 (MaxPooling1D)  (None, 500, 32)      0           conv1d_5[0][0]                   \n__________________________________________________________________________________________________\nbidirectional_4 (Bidirectional) (None, 500, 64)      16640       max_pooling1d_4[0][0]            \n__________________________________________________________________________________________________\nbidirectional_5 (Bidirectional) (None, 500, 64)      16640       max_pooling1d_5[0][0]            \n__________________________________________________________________________________________________\nattention_4 (attention)         (None, 64)           564         bidirectional_4[0][0]            \n__________________________________________________________________________________________________\nattention_5 (attention)         (None, 64)           564         bidirectional_5[0][0]            \n__________________________________________________________________________________________________\nflatten_4 (Flatten)             (None, 64)           0           attention_4[0][0]                \n__________________________________________________________________________________________________\nflatten_5 (Flatten)             (None, 64)           0           attention_5[0][0]                \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 128)          0           flatten_4[0][0]                  \n                                                                 flatten_5[0][0]                  \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 256)          33024       concatenate_2[0][0]              \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 128)          32896       dense_2[0][0]                    \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 3)            387         dense_3[0][0]                    \n==================================================================================================\nTotal params: 133,675\nTrainable params: 133,675\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "# Model Architecture\n",
    "input_target = Input(shape=(1000,))\n",
    "emb_target = Embedding(21, 128, input_length=max_length)(input_target) \n",
    "conv_target_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(emb_target)\n",
    "pool_target_1 = MaxPooling1D(pool_size=2)(conv_target_1)\n",
    "att_in_target = Bidirectional(LSTM(32, kernel_regularizer=l2(0.01), return_sequences=True, recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))(pool_target_1)\n",
    "att_out_target = attention()(att_in_target)\n",
    "flat_1_target = Flatten()(att_out_target)\n",
    "\n",
    "# softmax classifier\n",
    "#x_output_target = Dense(3, activation='softmax')(att_in_target)\n",
    "\n",
    "input_drug = Input(shape=(1000,))\n",
    "emb_drug = Embedding(44, 128, input_length=max_length)(input_drug) \n",
    "conv_drug_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(emb_drug)\n",
    "pool_drug_1 = MaxPooling1D(pool_size=2)(conv_drug_1)\n",
    "att_in_drug = Bidirectional(LSTM(32, kernel_regularizer=l2(0.01), return_sequences=True, recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))(pool_drug_1)\n",
    "att_out_drug = attention()(att_in_drug)\n",
    "flat_1_drug = Flatten()(att_out_drug)\n",
    "\n",
    "concat = Concatenate()([flat_1_target,flat_1_drug])\n",
    "\n",
    "dense_1 = Dense(256, activation = 'relu',kernel_initializer='glorot_normal')(concat)\n",
    "dense_2 = Dense(128, activation = 'relu',kernel_initializer='glorot_normal')(dense_1)\n",
    "\n",
    "# softmax classifier\n",
    "x_output = Dense(3, activation='softmax')(dense_2)\n",
    "\n",
    "model1 = Model(inputs=[input_target, input_drug], outputs=x_output)\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n 55/384 [===>..........................] - ETA: 13:42 - loss: 3.4658 - accuracy: 0.4878"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c11ed5ffe4d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     ))\n",
      "\u001b[1;32mf:\\Projects\\20202507_dNNDR\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Projects\\20202507_dNNDR\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Projects\\20202507_dNNDR\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Projects\\20202507_dNNDR\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Projects\\20202507_dNNDR\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Projects\\20202507_dNNDR\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Projects\\20202507_dNNDR\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Projects\\20202507_dNNDR\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mf:\\Projects\\20202507_dNNDR\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories.append(model1.fit(\n",
    "    [train_pad_target, train_pad_drug], y_train,\n",
    "    epochs=100, batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model history\n",
    "obj.plot_history(histories[0])"
   ]
  }
 ]
}